---
title: "Walkthough guide to haPLOType"
author: "Thomas Ng and Eric C. Anderson"
date: "`r Sys.Date()`"
output:
  rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{microhaPlot walkthrough}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

`microhaplot` comes pre-loaded with some wonderful, real example data to get you started to learn about its functionality.
This vignette will walk you through a look at the example data and introduce you to many of the features of `haPLOType`.

The data that we will be exploring together are called `fish2_example.rds` and will appear in the Shiny app dropdown menu after installation following the README on GitHub (reproduce that here, later).  These data are from a MiSeq run with about 100 amplicons sequenced on close to 300 individual fish.  The fish are all from a single population, but, in order to demonstrate the "group" attribute, we put half of the fish into the group "pop1" and the other half of the fish into
the group "pop2".

## The Basics

The first thing you will want to get straight is that there are essentially four different "panels" on the haPLOType viewer that will always stay with you.  From top to bottom they are:

1. **The interaction tabset:**  These are the three tabs that live at the top of the page with the light
blue background.  Any one of the three: ">field selection", "+read criteria", and "+locus annotation"
can be selected.  Whichever one is selected determines the content of the panel directly beneath---the
user input panel, the panel with the light gray background.  

    a. **field Selection tab:** If the "> field selection" is selected, then the user input panel will include dropdown boxes that let you choose a group, locus, or individual(s) that you wish to focus on (this choice affects what is shown in different plots and outputs,
etc.) It also includes "backwards-and-forwards" buttons, "<" and ">", that let you step individually through
loci (the buttons to the right* of "Locus") or through individuals (fish in this case---the buttons to the
right* of the "Indiv" dropdown box.) These are very useful when you want to work your way through each
locus individually and choose those that do (and do not) appear to be reliable enough to include in a
panel of amplicons. *The location and relative position of each button might change pending on the width of the viewing window.   

    b. **read criteria tab:** In the "+ read criteria" tab, you are given the ability to define the minimal read depth and minimal allelic ratio that microhaplotype reads have to pass through.

        * Minimal Read depth defines the minimal number of reads that are observed for a particular microhaplotype in a single individual's locus. It can only take positive values.
        * The allelic ratio (allelic balance) is defined as the ratio of observed read depth of a microhaplotype to read depth of the most common microhaplotype. Again, the value is drawn at a single locus on an individual basis.

        > Ideally, for the homozygous case, you are expected to see the true microhaplotype to have a large read depth and allelic ratio of one. The false microhaplotypes will be in the background with low read depth and allelic ratio close to zero. As for heterozygous case, the two true microhaplotypes ideally should have large and similar number of reads which means that their allelic ratio should be one or close to one.

        So once you finish defining the minimal criteria, you can apply it with the "apply" button.
        You can also save this criteria setup for future re-visit by clicking the "save" button.
        There are other options that located on the right hand side that gives you more ways to define the critera. Details for each of the options are shown if you hover your pointer over it.

    c. **locus annotation:** This tab is for users to keep track of whether a certain locus should be tossed out based on its quality. There is also a small textbox that lets you to put any comment regarding the locus group. Remember to press the save button for submission. All of these annotation information can be retreived under the table selection for "locus annotation" under `Output` tab.


1. **The main body panel:** This occupies most of haPLOType's screen real estate.  It is where the actual
plots, tables, and other results are rendered.  What gets rendered here depends on which main body panel
has been chosen.  That choice is made using the *main panel choice tabset* described below.
1. The **main panel choice tabset** is always down at the bottom, and is a tabset that allows you to choose the contents
of the main body panel:
    a. *Panel:* which data set do you want to explore.  When you started haPLOType it should have had the
    dropdown menu for "fish2_example.rds".
    b. *Summary Info: * let's you choose plot-summaries that give you a good overview of the characteristics of groups, individuals, or loci.
    c. *Filter Analysis:* let's you explore 1) a tabular summary (the "Broad Summary") of the number of haplotypes observed and
    individuals called subject to different levels of filtering. 2) "Criteria Breakdown" shows the distribution of read depths
    and the allelic depth ratios of different haplotypes at individual loci, and 3) "Microhap Summaries" shows haplotype frequencies,
    and a visual summary of conformance to Hardy-Weinberg proportions of individual loci, and also portrays the position of the
    variants within the sequence.
    d. *Inferential Analysis: * is a wrapper that integrates with the "Sr.MicroHap" Bayesian haplotype caller which is
    in development still.
    e. *Output: * provides a place to get a number of tabular views of the data that are sortable and searchable.  This can
    be very useful when you want to dig into the nitty-gritty details of the short read data.  It also allows you to download
    filtered and called data and genotypes for later analysis.
    f. *About haPlot: * provides a little background about haplot and how to cite it and whom to contact about it.

With that background we are ready to start exploring the example data!

## Mission one: An overview of loci

The first thing we are going to do is get an overview of the data with no filtering, focusing on
different loci.  Not surprisingly, for this we choose *Summary Info --> By Locus*.  We also want to
make sure that we are starting from the defaults in ">field selection" (ALL group, ALL loci, ALL individuals),
and under "+read criteria" you want to ensure that "Minimal Read Depth" and "Minimal Allelic Ratio" are
both set to 0.  (If you had changed these before then once you set them back to 0 you should hit the "apply"
button to apply the changes.)

Anyway, choosing *Summary Info --> By Locus* will give you four plots.  By default, only the first 15 loci are
represented (the reason of this is that if you have many loci, you don't want to end up waiting fo an
eternity to have the final plots rendered.)  You can change the number of loci shown using the
"Display" dropdown menu that lives just beneath the user input panel.  You can also choose to go through
the loci, 15 at a time by choosing which page to go to using the "Page" selector to the right of the
"Display" selector.  

The four figures shown in this By Locus summary are, from left to right:

1. The distribution of the number of haplotypes observed per individual.  Recall that these are subject to the
current filters, of which there are none, so each haplotype, even if it is only observed at a read depth of
1 read in an individual is counted as observed.  This plot is a bubble plot that essentially is giving
histogram-like information.  The y-axis has a different loci on different lines.  The x-axis is the number of unique haplotypes
and the size of the bubbles (and their shading) indicate how many individuals in the data set had the given
number of unique haplotypes.    It is particularly revealing to have a peek at the locus `tag_id_1166`.  Most individuals
have a large number of different haplotypes, likely occurring at very low read depths.  At any rate, this
plot makes it clear that there are a lot of low-read-depth sequences that are superfluous and incorrect.

1. Moving to the right is another figure that has loci arranged on the y-axis and number of haplotypes on the
x-axis.  However, in this case, the number is counting the total number of unique haplotypes observed at the
locus when only the two highest-read-depth haplotypes are recorded per individual.

1. Moving right again is a plot with light blue points indicating the fraction of individuals that have
sufficient read depth to allow a genotypes to be called given the current settings of the filters.  
Obviously since there is filtering, every locus is going to have a genotype called at every indvidual.

1. The final plot (the furthest right) just shows violin plots expressing the distribution of read depths at
each locus across the individuals.  Notice that the x-axis is on a log scale.  The plus denotes the median read
depth.  

### Look at all of the loci

Now that we know what all of these plots mean, let's have a look at all of the loci at once.  We do
this by merely choossing "ALL" in the "Display" dropdown menu.  From this we see that most loci have a
read depth greater than 20 or more at all the indidividuals.  Also there is a huge amount of
variation across loci in the number of recorded haplotypes per individual.  Clearly since any
diploid individual will have at most two distinct haplotypes at a locus, most of these haplotypes
are spurious, and we can hope that most of them are at very low read depths and will be filtered out.
We will investigate that.

### Let's apply some filters

Here is the moment we have all been waiting for.  We have been looking at our data in a totally unfiltered state---effectively regarding
a haplotype with 1 read to be on an equal footing with one having, say, 1000 reads in an individual.  There are two, simple, chief
filtering methods in haplot.  The first is to discard haplotypes from individuals if they occur in fewer than a certain number
of reads (The "Minimal Read Depth" criterion).  The second is to discard haplotypes from individauls if their read depth is less than a given fraction of the haplotype
with the highest read depth in the individual (The "Minimal Allelic Ratio" criterion).  Choose 25 for the Minimal Read Depth and
choose 0.2 for the Minimal Allele Ratio, and then hit "Apply".  

Once those filters take effect we find that most individuals are observed to carry one or two haplotypes at each locus.  Some loci
have more haplotypes that that observed in some individuals.  We will want to check up on those later.  Some of the loci clearly did
not sequence well.  For example `tag_id_1511`.  To see an expanded view of a few loci, you can highlight (with a click drag) their
rows in the left hand figure and then double click those to get a zoomed in view.  To zoom back out, to be able to see all
the loci, just double click the body of the left figure.  

## Mission Two: An overview of individauls

We can take those same filters we just applied and get a good overview of our sequencing data on an
individual basis.  Go ahead of choose *Summary Info-->By Individual*.  from the main panel choice
tabset.  The initial screen that comes up includes only 15 of the individuals.  We can change that
by choosing "ALL" in the "Display ----- indivs" dropdown.

This "By Individuals" summary view of the data provides four different plots.  From left to right they
are:

1.  The ratio of the haplotype with 2nd highest read depth to the haplotype with highest read depth.  
In this plot, the y-axis denotes individual, the x-axis represents the ratio (it goes from 0 to 1)
and each locus is represented as a bubble.  The size of the bubble is scaled to some function of
read depth (I believe) but it is hard to place that on an absolute scale.  The main take home message
from this plot is that for most individuals at most loci the two highest-read depth haplotypes have
fairly similar read depths.  For example a ratio of 0.75 indicates that if the haplotype with highest
read depth at a locus in an individual was 100 reads, then, the haplotype with second highest read
depth was 75 reads.  

1. The number of haplotypes observed in each individual.  This is a bubble plot that expresses the relative
number of loci at which 1, 2, 3, etc haplotypes were observed after filtering.  

1. The number of loci within the individual with sufficient read depth to call a genotype (given the current filters).

1. The distribution over read depths at the loci in the individual.  These are portrayed as violin plots with individual
values as dots within them.


It should be noted that the colors of the bubbles on the left-most graph indicate the different
groups that the individuals fall into.  This is particularly useful when individuals from different
populations or species are in the alignment.  In the case of our example data, we have merely
assigned half of the individuals to be from "pop1" and the other half from "pop2".

### Spotting some dodgy individuals

This overview of all the individuals gives us a good chance to spot a few problem fish
right off the bat.  Just scanning down the fraction of loci that the individuals might be
called at, it is clear that s45 and s277 have not been well sequenced.  That is clear by
looking at the distribution of read depths across loci.  Perhaps even more intriguing is
individual s288 that seems to have pretty reasonable read depths, but very poor allelic
balance.  

### Looking at the raw counts for s288

At this point, we may as well have a tour of the facilities for visualizing the data for
in tabular format.  If we want to see the tabular data for individual s288, it
is fairly straightforward --- choose "Output" from the main panel choice tabset.   By
default this will show a few lines of the "Observed variants (unfiltered)" table.
You can change which table is viewed using the "Select Table" dropdown, but unfiltered
observed variants is great for now.  

In the search box on the right, enter s288 and hit return.  This will filter the table to only
those rows that include s288.  Once that is done, click on the "locus" column heading to
sort entries by locus.  Voila! Now you can peruse all the observed variants and their read
depths at this individual s288.  Where is says "Show 15 entries" you should change the "15"
to "All".  This will give you a single scrollable window of all the entries for s288.  Note that
the column "Haplo" gives the sequence of the reads at the variable positions.  These are
essentially the haplotypic states of the reads.

Going through the data for 288, it is clear that there will be some genotypes that are not
straightforward to call.  For example, at locus `tag_id_879` there are three different
haplotypes with read depths over 50:  128 reads of CCCTCTG, 100 reads of CCCTCAG, and
57 of GCCCCTG.  That is clearly going to be difficult to genotype.  Perhaps this
individual has contaminated DNA or represents two individuals that were barcoded equivalently.
It probably should be tossed out of the final data set.

### Raw count data for a less dodgy individual?

So, the data for s288 was a little disquieting, but recall that was an individual that
looked pathological from the very beginning.  So, what if we look at the raw count
data for an individual that doesn't look so dodgy?  This will be a good exercise to
build up some intuition about how genotyping might be done with microhaplotype read
data.

Let's have a closer look at individual s95.  From the overview, this is an inividual with
reasonably clean, abundant reads.  We can filter on this individual merely by replacing
"s288" in the search box with "s95".  A cursory glance at the results for this individual
show us what appears to be an individual that will be very easy to genotype:  there are never
more than two haplotypes at high read depth but there is always at least one haplotype
at high read depth.  When two haplotypes are at high read depth, their read depths
are largely quite similar.  

## Looking over different loci

When we start to get down to the level of assessing how well it appears different amplicons will
allow genotyping via microhaplotypes, it is time to turn to the "Filter Analysis" panel choice.
First, go ahead and choose *Filter Analysis --> Broad Summary*.  This view gives you a tabular
perspective on the outcome of different filtering choices on the total number of haplotypes
recorded in the data set.  The field selection choices that are present are applied here. So,
if ALL loci are selected, then it counts up the total number of haplotypes typed and the total
number of individuals typed at all loci.  If you select just one locus, the results reflect that
one locus.

With that in mind, choose the first locus in the dropdown menu: `Plate_1_A01_Sat_GW603857_consensus`
and see how that changes the broad summary.  Note that across a broad range of the two filtering
options (minimum read depth and minimal allelic balance) there are four haplotyes in total discovered.

For a more detailed view of the information associated with this locus (especially relative to the
filtering choices) you can select *Filter Analysis --> Distribution Plots*.  This view shows
a histogram of read depths and allele balance ratios for reads assigned to each indiduals, and it shows
these when broken down by haplotype.  The filtering choices in effect appear as dashed red lines.

To see how the inferred haplotypes look in terms of haplotype frequencies, and also how the genotypes
look in terms of Hardy-Weinberg equilibrium, you can choose *Filter Analysis --> Finalized Haplotype*.
This view consists of four figures.  The first, in the upper left simply shows the frequencies (and the total read depth) of
different haplotypes.  The right hand part of that same top figure shows the relationship between the
observed frequency of different genotypes and the expected frequencies under Hardy-Weinberg equilibrium.
The individuals used in creating these summaries depends on which "Group" is chosen.  In this case we have
"ALL" chosen, and that is fine because the two groups are essentially identical, genetically.  However,
if we were dealing with groups that were genetically differentiated, we would not want to assess
conformance to Hardy-Weinberg proportions of a mixture of those different groups!  In such a case
it is worthwhile to look at one group at a time.

The expected number of different genotypes is shown by the oulines of circles and the observed number by the
filled, colored circles.  Green are homozygotes, orange are heterozygotes, and it should be relatively
self-explanatory.  There is not a scale, but if you click in the center of any of the genotypes with
observed (non-zero) counts, you will be told (in the upper left of the figure) what the expected and
observed numbers were for that genotype.  These plots are not meant to provide a stringent test
of departures from Hardy-Weinberg equilibrium, but do allow the user to diagnose loci that are
grotesquely far out of Hardy-Weinberg equilibrium.

Below the haplotype frequencies and HW conformance plots you will find a simple bubble plot
expressing haplotype frequencies in the different groups.  In the case of the example data there
are only two different groups and they have very similar allele frequencies.  This plot becomes more
useful when one is comparing allele frequencies across many different groups.

Finally, you may need to scroll down to see the final figure in this display.  It is a representation of the
haplotype sequences, their frequencies, and the positions of the variants within them along each amplicon.

## Output of data

We have already witnessed how to use the *Output* panel to look at the raw data.  It is also possible to
download filtered, unfiltered, and processed data from this view using the "Download Data" button.  That
seems to be working fine, except for the reported individual haplotypes.

## Locus annotation

The program can be used to annotate different loci (and assign filtering criteria to them). This
annotation can be done using the "+locus annotation" interaction tabset, and the results saved
by downloading the locus annotation data from the *Outputs* panel.
